---
layout: post
title: 《浏览器工作原理与实践》系列笔记 - 浏览器中的网络
tags: [browser]
---

谈到浏览器的网络，就绕不开 HTTP，它是浏览器中应用最多的协议，是浏览器和服务器之间通信的语言，也是互联网的基石

随着浏览器发展，为了适合新的形式也在持续发展。

了解 HTTP 最好的方法就是了解它的发展史。接下来会从以浏览器的发展视角讲讲 HTTP 的研究，分别是

- 即将完成使命的 HTTP/1
- 走向我们的 HTTP/2
- 未来的 HTTP/3

# HTTP1：HTTP 性能优化

这节主要讲 HTTP/1.1，先来了解下发展史，然后介绍遇到的各种瓶颈，以及解决方法

## 超文本传输协议 HTTP/0.9

这个协议是 1991 年提出的，最早的 HTTP 协议，主要用于学术，也是简单的在网络之间传输 HTML 文件就好了，所以也叫超文本传输协议。协议简单，采用请求响应模式，客户端发请求，服务器返回数据。它的主要流程如下：

![](/img/posts/browser/http/1.png)

当初传送的 HTML 文件也很小， HTTP/0.9 主要有下面几个特点

1. 只有一个请求行，没有请求头和请求体。主要一个请求行就可以表示所有的客户端需求了
2. 响应数据也没有响应头，只有响应行和响应体里面的数据
3. 返回的数据内容是 ASCII 字节流传送的，因为当时也只有 HTML 格式的文件

## 被浏览器推动的 HTTP/1.0

1994 年，出现拨号上网服务，网景推出了第一款浏览器，万维网不仅限于学术交流，进入高速发展阶段。随后 W3C 和 HTTP 工作组成立，致力于 HTTP 的发展和改进

万维网的高速发展带来很多新的需求，HTTP/0.9 已经不适合新型网络的发展了，需要一个新的协议来支撑，这就是 HTTP/1.0 诞生的原因。我们先看看新型网络需要什么需求

浏览器中不再只有 HTML 文件，还包含了 JavaScript CSS 图片 音频 视频，因此支持多文件类型的下载是核心的诉求，文件格式也不应该局限于 ASCII，还有很多其他编码的文件

## 如何实现多文件的下载？

HTTP/0.9 只有一个请求行，无法告诉服务器更多的信息，比如文件类型和文件编码。同样的，服务器返回的也只有数据和响应行，没有办法告知更多关于返回数据的信息

于是在 HTTP/1.0 加入了请求头和响应头，以 key-value 形式保存，发送请求会先加上请求头，返回的数据也会先看到响应头

![](/img/posts/browser/http/2.png)

HTTP/1.0 是通过什么手段来支持多种不同的文件类型的？我们需要解决下面几个问题

- 浏览器需要知道服务器返回的数据类型是什么，才能根据类型进行不同的处理
- 万维网支持的类型越来越多，单个文件的体积也越来越大，为了减轻传输的性能，需要对数据进行压缩后在传输，浏览器需要知道服务器的压缩方法
- 万维网是支持全球的，不同的地方有不同的语言版本，所以浏览器需要告知服务器需要的语言版本
- 最后浏览器也需要知道文件的编码格式

于是，HTTP/1.0 的一个请求可能是下面这样的，告知服务器需要返回什么类型的文件，期望的文件的编码，能够接收的压缩方式，以及期望的的语言版本

```
accept: text/html
accept-encoding: gzip, deflate, br
accept-Charset: ISO-8859-1,utf-8
accept-language: zh-CN, zh
```

而服务器也会新增响应头，如下例子，告知了使用的压缩方法，已经返回的文件格式和编码格式

```
content-encoding: br
content-type: text/html; charset=UTF-8
```

那么浏览器就会使用 br 的方式进行解压，按照 utf-8 的编码格式处理文件，按照 text/html 的方法解析 HTML 文件

另外也根据需求引入了一些其他的功能，基本都是通过请求头和响应头来实现的

- 引入了状态码，主要当初有时候请求无法成功等，需要告诉浏览器处理结果
- 减轻服务器的压力，HTTP/1.0 提供了 cache 的能力，缓存已经下载的数据
- 服务器需要统计客户端的信息，所以请求头还加入了用户代理信息字段

## 缝缝补补的 HTTP/1.1

需求继续在迭代，很快 HTTP/1.0 也很多需求不能满足，HTTP/1.1 在其基础上继续做了大量的更新。我们来看看 HTTP/1.0 遇到的问题，以及怎么解决的

### 改进持久连接

HTTP/1.0 每次 HTTP 请求，都需要进过 TCP 建立连接，传输数据，断开连接的过程

![](/img/posts/browser/http/3.png)

一开始传输的内容不多，文件比较少，问题不大，但是随着网页的图片越来越多，如果每个请求都这么处理的话，开销非常大

于是在 HTTP/1.1 增加了持久连接的方法，在一个 TCP 连接上可以传输多个 HTTP 请求，只要浏览器或者服务器没有明确断开的话，就一直保持

![](/img/posts/browser/http/4.png)

这样有效的减少了 TCP 建立连接和断开连接的次数，减少了服务器的压力

持久连接在 HTTP/1.1 是默认打开的，如果不想使用的话可以使用 Connect: close 关闭。目前浏览器对于同一个域名，最多可以开启 6 个持久连接

### 不成熟的 HTTP 管线化

持久连接可以减少建立连接和断开连接的次数，但是要等待前面的请求返回才能进行下一次的请求，如果某次请求由于一些原因无法快速返回的话，就会阻塞后面的请求，这就是著名的队头阻塞问题

HTTP/1.1 试图通过管线化技术解决这个问题，多个 HTTP 请求整批提交给服务器的技术，虽然可以整批提交，但是还是需要按照请求顺序回复浏览器的请求

### 提供虚拟主机支持

HTTP/1.0 每一个域名绑定了唯一的 IP 地址，一个服务器只能支持一个域名，随着虚拟机的发展，需要实现一台物理主机上绑定多个虚拟机，每个虚拟机有自己的单独的域名，这些单独的域名都用同一个 IP 地址

因此 HTTP/1.1 增加了 Host 字段，用来表明现在的域名地址，服务器可以根据不同的 Host 进行处理

### 对动态生成的内容进行支持

HTTP/1.0 需要在响应头设置数据的大小，比如 Content-Length: 901，浏览器可以根据这个信息来进行数据的接收，不过后来很多的内容是动态生成的，传输前并不知道最终的数据大小，导致浏览器不知道什么时候能接收完所有的文件数据

HTTP/1.1 引入了 chunk transfer 机制解决了这个问题，服务器把数据切割成若干个任意大小的数据，每个数据块发送的时候会附上上一个数据块的长度，最后使用一个零长度的块表示数据完成的标志，这样就提供了动态内容的支持了

### 客户端 cookie，安全机制

HTTP/1.1 引入了客户端 cookie 机制和安全机制

## 总结

- HTTP/0.9 因为需求简单，实现也简单
- 随着万维网高速发展，核心需求是增加多文件类型的支持，HTTP/1.0 引入了请求头和响应头，也引入了新的 Cache 机制，用户代理，状态码等基础信息
- 人们对传输的要求越来越高，HTTP/1.1 增加了持久连接，尝试管道化提升效率（但是最终放弃了），引入了 cookie，安全机制，虚拟主机的支持，动态内容的支持

虽然 HTTP/1.1 做了很多优化，但是还存在很多的痛点，需要 HTTP/2.0 去解决了

# HTTP2：如何提升网络速度

HTTP/1.1 主要做了下面三个优化：

- 持久连接
- 为每个域名维护 6 个持久 TCP 连接
- 使用 CDN 实现域名分片机制

我们看下最后一点

![](/img/posts/browser/http/5.png)

引入了 CDN，同时为每个域名维护 6 个连接，大大减少了资源的下载时间。
如果使用单个 TCP 连接的话，下载 100 个资源所花费的时间为 `100 * n * RTT`
如果通过上面的手段，整个时间缩短为 `100 * n * RTT/(6 * CDN 个数)`

## HTTP/1.1 的主要问题

带带宽的利用率不高，是核心问题之一

带宽指的是每秒最多可以接收或者发送的字节数，能发送的最大字节数上限叫做上行带宽，能接受的最大字节数叫做下行带宽

HTTP/1.1 很难把带宽用满，比如我们说 100M 带宽，实际下载速度能达到 12.5M/s。采用 HTTP/1.1 的话最大只能到 2.5M/s，这个问题的主要原因有下面几点：

### TCP 的慢启动

一旦 TCP 连接完成，进入数据发送状态，一开始 TCP 采用一个很慢的速度去发送数据，然后慢慢加快速度，直到达到一个理想的状态，这个过程称之为慢启动

就像开车一样，一开始速度为 0，慢慢加速直到稳定的车速 🚗

慢启动 TCP 是为了减少网络阻塞的一种策略，我们无法改变

而慢启动带来性能的问题是因为我们常用的资源文件本身不大，比如 HTML CSS JavaScript 文件，通常建立好连接就要发起请求，但是因为慢启动的原因，耗费的时间比正常时间多很多，也推迟了宝贵的首屏加载速度了

### 同时开启了多条 TCP 连接，那么这些连接会竞争固定的带宽

同时建立了多条 TCP 连接，带宽充足的时候，发送速度（接收的情况一样）会慢慢上升，如果带宽不足的话，TCP 会减慢发送的速度。

如果一个页面 200 个文件，使用了 3 个 CDN，那么加载的时候启用了 `6 * 3` 个 TCP 连接来下载文件，当发现带宽不足的时候，各个 TCP 连接都动态减慢速度

这样会出现一个问题，因为一个 TCP 连接下载的是关键资源，比如 CSS JavaScript，而有的是下载图片 视频等资源。

但是多条 TCP 连接不能协商哪个关键资源优先下载，那么就会影响关键资源等下载了

### HTTP/1.1 头部阻塞问题

虽然可以公用一条 TCP 连接，但是同一时刻只能处理一个 HTTP 请求，如果一个请求一直卡住，那机会阻塞所有请求。那么这个时候带宽，CPU 也在白白浪费了

而且在浏览器生成页面等过程，也希望能提前收到数据，进行一些预处理，比如接收到图片先进行编解码操作，真正需要的时候能马上使用，让用户感觉整体速度提升了

头部阻塞使得这些资源不能并行处理，非常不利于优化

## HTTP/2.0 多用复用

- 慢启动和 TCP 连接之间相互竞争带宽是由于 TCP 本身的机制导致的
- 而队头阻塞是由于 HTTP/1.1 的机制导致的

怎么解决呢？

HTTP/2.0 的思路是一个域名只使用一条 TCP 长连接来传输数据，那么慢启动过程就只有一次，也避免了多个 TCP 连接带来的带宽竞争问题

HTTP/2.0 也需要去实现资源的并行请求，任何时候发送请求给服务器，都不需要等待其他的请求，随时返回数据给浏览器

HTTP/2.0 的方案总结如下：一个域名只使用一个 TCP 长连接和消除队头阻塞问题。示意图如下：

![](/img/posts/browser/http/6.png)

这也是 HTTP/2.0 最核心，最重要和具有颠覆性的多路复用机制。可以发现每个 HTTP 请求会有一个对应的 ID，比如 stream1 代表 index.html 请求，stream2 代表 foo.css 请求。浏览器可以随时发送请求

服务器接收到以后会按照喜好来决定优先返回的内容，比如如果已经准备好了 index.html 和 bar.js 的响应头信息，那么接收到请求的时候里面把它们的响应头信息返回，然后再把它们的响应体信息返回

之所以可以随意发送，是因为每份数据都有对应的 ID，浏览器接收到数据以后会根据 ID 拼接为完整的响应数据

HTTP/2.0 采用了多路复用的技术可以把请求分成一帧一帧去传输，这样带来的一个好处是当接收到一个优先级高的请求， 比如 JavaScript 或者 CSS 关键资源的请求，服务器可以暂停现在的处理优先处理这部分的请求

## 多路复用的实现

![](/img/posts/browser/http/7.png)

多路复用是怎么实现的呢？

HTTP/2.0 新增了一个二进制分帧层，我们看看现在的过程

- 浏览器准备好请求行，请求头，请求体（如果有的话）
- 这些数据经过二进制分帧层，会被转换成带有请求 ID 编号的帧
- 服务器收到所有帧数据以后，会把所有相同 ID 的帧合并为一条完整的请求信息
- 服务器处理该请求，并把处理好的响应行，响应头和响应体发送给二进制分帧层
- 通用响应数据转成一个个带有响应 ID 编号的帧，返回给浏览器
- 接收到响应帧以后根据 ID 把帧数据交给对应的请求对象

通过引入二进制分帧层，来实现了多路复用

HTTP/2.0 对比 HTTP/1.1 改变的只是传输的方式

## HTTP/2.0 其他特性

多路复用并行传输是 HTTP/2.0 的最主要特点，建立在二进制分帧层的基础之上的

而在这个基础上还增加了一些其他新的特性

### 设置请求的优先级

HTTP/2.0 提供了请求优先级，在发送请求的时候标上优先级，服务器收到以后也会优先处理

### 服务器推送

服务器可以直接推送消息给浏览器，比如当用户请求了一个 HTML 文件以后，服务器直到这个文件还需要后续引用的 JavaScript 文件和 CSS 文件，可以附带把这些文件一并发送给浏览器，当解析 HTML 的时候，能直接使用它们，这对于首屏加载速度是非常有意义的

### 头部压缩

对请求头和响应头进行了压缩。可能有时候觉得请求头不多，不需要压缩，但是发送请求的时候基本内容都是请求头信息，很少有请求体。如果有 100 个请求，把请求头信息压缩成原来的 20%，那也能提升不少的速度

## 总结

分析 HTTP/1.1 存在的问题：慢启动，多条 TCP 竞争，头部阻塞问题

HTTP/2.0 采用了多路复用对技术来解决这些问题，它是通过增加二进制分帧层来实现的，还能够设置资源的优先级，服务器推送，头部压缩等特性，大大提升了传输效率

HTTP/2.0 在 2015 年发布后，已经得到了广泛的应用，国内很多网站已经实现了 HTTP/2.0 的部署，能带来大概 20%～ 60%的效率提升
